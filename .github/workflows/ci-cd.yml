# =============================================================================
# AZALS - Pipeline CI/CD ELITE UNIFIE
# =============================================================================
# Pipeline enterprise-grade avec:
# - Tests avec coverage (PostgreSQL, Redis)
# - Analyse de securite multi-couche (SAST, SCA, secrets, containers)
# - Qualite de code (lint, format, types)
# - Build Docker avec cache et scanning
# - Deploy staging/production avec rollback
# - Notifications et rapports
# =============================================================================

name: "AZALS CI/CD Elite"

on:
  push:
    branches:
      - main
      - develop
      - 'feature/**'
      - 'fix/**'
      - 'audit/**'
      - 'claude/**'
  pull_request:
    branches:
      - main
      - develop
  workflow_dispatch:
    inputs:
      skip_tests:
        description: 'Skip tests (emergency only)'
        required: false
        default: 'false'
        type: boolean
      force_deploy:
        description: 'Force deployment'
        required: false
        default: 'false'
        type: boolean

# Un seul workflow par branche - annule les runs precedents
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '20'
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}
  COVERAGE_THRESHOLD: 70
  # Secrets de test (non-production)
  TEST_SECRET_KEY: "elite-test-key-for-ci-cd-pipeline-min32chars"
  TEST_DATABASE_URL: "postgresql://azals_test:azals_test_password@localhost:5432/azals_test"

jobs:
  # ===========================================================================
  # PHASE 1: ANALYSE STATIQUE (parallele)
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Lint Python avec Ruff
  # ---------------------------------------------------------------------------
  lint-python:
    name: "Lint Python"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Ruff
        run: pip install ruff

      - name: Run Ruff
        run: |
          ruff check app/ --output-format=github
          ruff check app/ --statistics

  # ---------------------------------------------------------------------------
  # Formatage avec Black et isort
  # ---------------------------------------------------------------------------
  format-check:
    name: "Format Check"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install formatters
        run: pip install black isort

      - name: Check Black formatting
        run: black --check --diff app/ || echo "::warning::Code needs formatting with Black"

      - name: Check isort imports
        run: isort --check-only --diff app/ || echo "::warning::Imports need sorting with isort"

  # ---------------------------------------------------------------------------
  # Type checking avec mypy
  # ---------------------------------------------------------------------------
  type-check:
    name: "Type Check"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install mypy types-python-dateutil types-redis

      - name: Run mypy
        run: mypy app/ --ignore-missing-imports --no-error-summary || true

  # ---------------------------------------------------------------------------
  # Validation architecture
  # ---------------------------------------------------------------------------
  architecture:
    name: "Architecture Validation"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Validate architecture
        run: |
          if [ -f "scripts/validate_architecture.py" ]; then
            python scripts/validate_architecture.py
          else
            echo "Architecture validation script not found, skipping"
          fi

  # ===========================================================================
  # PHASE 2: SECURITE (parallele avec Phase 1)
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # SAST avec Bandit
  # ---------------------------------------------------------------------------
  security-sast:
    name: "Security SAST"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Bandit
        run: pip install bandit

      - name: Run Bandit (high severity - blocking)
        run: |
          bandit -r app/ -ll -ii -x '**/tests/**' -f txt

      - name: Run Bandit (full report)
        run: |
          bandit -r app/ -f json -o bandit-report.json -x '**/tests/**' || true

      - name: Upload Bandit report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-security-report
          path: bandit-report.json
          retention-days: 30

  # ---------------------------------------------------------------------------
  # SCA - Vulnerabilites dependencies
  # ---------------------------------------------------------------------------
  security-sca:
    name: "Security SCA"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install pip-audit
        run: pip install pip-audit

      - name: Run pip-audit
        run: |
          pip-audit -r requirements.txt --format json --output pip-audit.json || true
          pip-audit -r requirements.txt --strict --desc on 2>&1 | tee pip-audit.txt || true

      - name: Check for critical vulnerabilities
        run: |
          if [ -f "pip-audit.json" ]; then
            CRITICAL=$(cat pip-audit.json | python3 -c "import json,sys; data=json.load(sys.stdin); print(len([v for v in data.get('dependencies', []) if any(vuln.get('fix_versions') for vuln in v.get('vulns', []))]))" 2>/dev/null || echo "0")
            echo "Critical vulnerabilities requiring updates: $CRITICAL"
            if [ "$CRITICAL" -gt "5" ]; then
              echo "::warning::Found $CRITICAL dependencies with available fixes"
            fi
          fi

      - name: Upload SCA report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: sca-report
          path: |
            pip-audit.json
            pip-audit.txt
          retention-days: 30

  # ---------------------------------------------------------------------------
  # Detection de secrets
  # ---------------------------------------------------------------------------
  secret-scan:
    name: "Secret Detection"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install detect-secrets
        run: pip install detect-secrets

      - name: Scan for secrets
        run: |
          detect-secrets scan app/ \
            --exclude-files '__pycache__|\.pyc|tests/|\.git' \
            > secrets-scan.json 2>&1 || true

          SECRETS_COUNT=$(cat secrets-scan.json | python3 -c "import json,sys; data=json.load(sys.stdin); print(sum(len(v) for v in data.get('results', {}).values()))" 2>/dev/null || echo "0")
          echo "Potential secrets found: $SECRETS_COUNT"

          if [ "$SECRETS_COUNT" -gt "0" ]; then
            echo "::warning::Found $SECRETS_COUNT potential secrets - review required"
            cat secrets-scan.json | python3 -c "import json,sys;data=json.load(sys.stdin);[print(f'  - {f}:{s.get(chr(108)+chr(105)+chr(110)+chr(101)+chr(95)+chr(110)+chr(117)+chr(109)+chr(98)+chr(101)+chr(114))}: {s.get(chr(116)+chr(121)+chr(112)+chr(101))}') for f,secs in data.get('results',{}).items() for s in secs]"
          fi

      - name: Upload secret scan
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: secrets-scan-report
          path: secrets-scan.json
          retention-days: 30

  # ---------------------------------------------------------------------------
  # License compliance
  # ---------------------------------------------------------------------------
  license-check:
    name: "License Compliance"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install pip-licenses
        run: pip install pip-licenses

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Check licenses
        run: |
          pip-licenses --format=markdown --output-file=licenses.md
          pip-licenses --format=json --output-file=licenses.json

          # Check for problematic licenses
          COPYLEFT=$(pip-licenses --format=json | python3 -c "import json,sys;data=json.load(sys.stdin);problematic=['GPL','AGPL','LGPL'];found=[p for p in data if any(lic in p.get('License','') for lic in problematic)];print(len(found))")

          if [ "$COPYLEFT" -gt "0" ]; then
            echo "::warning::Found $COPYLEFT packages with copyleft licenses - review for compatibility"
          fi

      - name: Upload license report
        uses: actions/upload-artifact@v4
        with:
          name: license-report
          path: |
            licenses.md
            licenses.json
          retention-days: 30

  # ===========================================================================
  # PHASE 3: TESTS (apres Phase 1 & 2 reussies)
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Tests unitaires et integration avec coverage
  # ---------------------------------------------------------------------------
  test:
    name: "Tests & Coverage"
    runs-on: ubuntu-latest
    needs: [lint-python, security-sast]
    if: ${{ github.event.inputs.skip_tests != 'true' }}

    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: azals_test
          POSTGRES_USER: azals_test
          POSTGRES_PASSWORD: azals_test_password
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio pytest-xdist coverage

      - name: Run tests with coverage
        env:
          ENVIRONMENT: test
          DATABASE_URL: ${{ env.TEST_DATABASE_URL }}
          SECRET_KEY: ${{ env.TEST_SECRET_KEY }}
          REDIS_URL: redis://localhost:6379/0
          ENCRYPTION_KEY: "test-encryption-key-32char!"
        run: |
          pytest tests/ -v \
            --cov=app \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-report=html \
            --cov-fail-under=${{ env.COVERAGE_THRESHOLD }} \
            -n auto \
            --dist loadfile

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        if: always()
        with:
          files: ./coverage.xml
          fail_ci_if_error: false
          verbose: true

      - name: Upload coverage HTML
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report
          path: htmlcov/
          retention-days: 14

      - name: Coverage summary
        if: always()
        run: |
          echo "## Coverage Report" >> $GITHUB_STEP_SUMMARY
          coverage report --format=markdown >> $GITHUB_STEP_SUMMARY || true

  # ---------------------------------------------------------------------------
  # Test des migrations Alembic
  # ---------------------------------------------------------------------------
  test-migrations:
    name: "Test Migrations"
    runs-on: ubuntu-latest
    needs: [lint-python]

    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: azals_migration_test
          POSTGRES_USER: azals_test
          POSTGRES_PASSWORD: azals_test_password
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install alembic psycopg2-binary

      - name: Test migrations up/down
        env:
          DATABASE_URL: postgresql://azals_test:azals_test_password@localhost:5432/azals_migration_test
        run: |
          # Upgrade to head
          alembic upgrade head

          # Downgrade 1 version (if possible)
          alembic downgrade -1 || echo "No previous migration to downgrade to"

          # Upgrade again
          alembic upgrade head

          echo "Migrations validated successfully"

  # ===========================================================================
  # PHASE 4: BUILD DOCKER (apres tests)
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Build et push image Docker
  # ---------------------------------------------------------------------------
  build:
    name: "Build Docker"
    runs-on: ubuntu-latest
    needs: [test, test-migrations, security-sca, license-check]
    if: github.event_name == 'push'

    permissions:
      contents: read
      packages: write
      security-events: write

    outputs:
      image_tag: ${{ steps.meta.outputs.tags }}
      image_digest: ${{ steps.build.outputs.digest }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix=sha-
            type=raw,value=latest,enable=${{ github.ref == 'refs/heads/main' }}

      - name: Build and push
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            VCS_REF=${{ github.sha }}
            VERSION=${{ github.ref_name }}

      - name: Generate SBOM
        uses: anchore/sbom-action@v0
        with:
          image: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:sha-${{ github.sha }}
          artifact-name: sbom-${{ github.sha }}.spdx.json
          output-file: sbom.spdx.json

      - name: Upload SBOM
        uses: actions/upload-artifact@v4
        with:
          name: sbom
          path: sbom.spdx.json
          retention-days: 90

      - name: Build summary
        run: |
          echo "## Docker Build" >> $GITHUB_STEP_SUMMARY
          echo "- Image: \`${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Tags: \`${{ steps.meta.outputs.tags }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- Digest: \`${{ steps.build.outputs.digest }}\`" >> $GITHUB_STEP_SUMMARY

  # ---------------------------------------------------------------------------
  # Scan vulnerabilites container avec Trivy
  # ---------------------------------------------------------------------------
  container-scan:
    name: "Container Security Scan"
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name == 'push'

    permissions:
      security-events: write

    steps:
      - uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: '${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:sha-${{ github.sha }}'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
          timeout: '10m'
        env:
          TRIVY_USERNAME: ${{ github.actor }}
          TRIVY_PASSWORD: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Upload Trivy report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: trivy-container-scan
          path: trivy-results.sarif
          retention-days: 30

  # ===========================================================================
  # PHASE 5: DEPLOIEMENT
  # ===========================================================================

  # ---------------------------------------------------------------------------
  # Deploy Staging (develop branch)
  # ---------------------------------------------------------------------------
  deploy-staging:
    name: "Deploy Staging"
    runs-on: ubuntu-latest
    needs: [build, container-scan]
    if: github.ref == 'refs/heads/develop'
    environment:
      name: staging
      url: ${{ vars.STAGING_URL }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install migration tools
        run: pip install alembic psycopg2-binary

      - name: Run database migrations
        env:
          DATABASE_URL: ${{ secrets.STAGING_DATABASE_URL }}
        run: |
          if [ -n "$DATABASE_URL" ]; then
            echo "Running staging migrations..."
            alembic upgrade head
          else
            echo "::warning::STAGING_DATABASE_URL not set"
          fi

      - name: Deploy to Render (Staging)
        env:
          RENDER_API_KEY: ${{ secrets.RENDER_API_KEY }}
          RENDER_SERVICE_ID: ${{ secrets.RENDER_STAGING_SERVICE_ID }}
        run: |
          if [ -n "$RENDER_API_KEY" ] && [ -n "$RENDER_SERVICE_ID" ]; then
            curl -X POST "https://api.render.com/v1/services/${RENDER_SERVICE_ID}/deploys" \
              -H "Authorization: Bearer ${RENDER_API_KEY}" \
              -H "Content-Type: application/json" \
              -d '{"clearCache": false}'
            echo "Staging deployment triggered"
          else
            echo "::warning::Render credentials not set"
          fi

      - name: Wait and smoke test
        env:
          STAGING_URL: ${{ vars.STAGING_URL }}
        run: |
          if [ -n "$STAGING_URL" ]; then
            sleep 60

            # Health check
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "${STAGING_URL}/health" || echo "000")
            if [ "$HTTP_CODE" = "200" ]; then
              echo "Health check: PASS"
            else
              echo "::error::Health check failed (HTTP $HTTP_CODE)"
              exit 1
            fi

            # API docs
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "${STAGING_URL}/docs" || echo "000")
            echo "API docs: HTTP $HTTP_CODE"
          fi

      - name: Staging summary
        run: |
          echo "## Staging Deployment" >> $GITHUB_STEP_SUMMARY
          echo "- Environment: staging" >> $GITHUB_STEP_SUMMARY
          echo "- URL: ${{ vars.STAGING_URL }}" >> $GITHUB_STEP_SUMMARY
          echo "- Commit: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY

  # ---------------------------------------------------------------------------
  # Deploy Production (main branch)
  # ---------------------------------------------------------------------------
  deploy-production:
    name: "Deploy Production"
    runs-on: ubuntu-latest
    needs: [build, container-scan]
    if: github.ref == 'refs/heads/main'
    environment:
      name: production
      url: ${{ vars.PRODUCTION_URL }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install migration tools
        run: pip install alembic psycopg2-binary sqlalchemy

      - name: Run database migrations
        env:
          DATABASE_URL: ${{ secrets.PRODUCTION_DATABASE_URL }}
        run: |
          if [ -n "$DATABASE_URL" ]; then
            echo "Running production migrations..."
            alembic upgrade head
          else
            echo "::warning::PRODUCTION_DATABASE_URL not set"
          fi

      - name: Deploy to Render (Production)
        env:
          RENDER_API_KEY: ${{ secrets.RENDER_API_KEY }}
          RENDER_SERVICE_ID: ${{ secrets.RENDER_PRODUCTION_SERVICE_ID }}
        run: |
          if [ -n "$RENDER_API_KEY" ] && [ -n "$RENDER_SERVICE_ID" ]; then
            curl -X POST "https://api.render.com/v1/services/${RENDER_SERVICE_ID}/deploys" \
              -H "Authorization: Bearer ${RENDER_API_KEY}" \
              -H "Content-Type: application/json" \
              -d '{"clearCache": false}'
            echo "Production deployment triggered"
          else
            echo "::warning::Render credentials not set"
          fi

      - name: Wait and smoke test
        env:
          PRODUCTION_URL: ${{ vars.PRODUCTION_URL }}
        run: |
          if [ -n "$PRODUCTION_URL" ]; then
            sleep 90

            # Health check
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "${PRODUCTION_URL}/health" || echo "000")
            if [ "$HTTP_CODE" = "200" ]; then
              echo "Health check: PASS"
            else
              echo "::error::Health check failed (HTTP $HTTP_CODE)"
              exit 1
            fi

            # API docs
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "${PRODUCTION_URL}/docs" || echo "000")
            echo "API docs: HTTP $HTTP_CODE"

            # Metrics
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" "${PRODUCTION_URL}/metrics" || echo "000")
            echo "Metrics: HTTP $HTTP_CODE"
          fi

      - name: Notify success
        if: success()
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
        run: |
          if [ -n "$SLACK_WEBHOOK" ]; then
            curl -X POST "$SLACK_WEBHOOK" \
              -H 'Content-type: application/json' \
              -d '{
                "text": "AZALS Production Deployment Successful",
                "attachments": [{
                  "color": "good",
                  "fields": [
                    {"title": "Commit", "value": "${{ github.sha }}", "short": true},
                    {"title": "Branch", "value": "main", "short": true}
                  ]
                }]
              }'
          fi

      - name: Notify failure
        if: failure()
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
        run: |
          if [ -n "$SLACK_WEBHOOK" ]; then
            curl -X POST "$SLACK_WEBHOOK" \
              -H 'Content-type: application/json' \
              -d '{
                "text": "AZALS Production Deployment FAILED",
                "attachments": [{
                  "color": "danger",
                  "fields": [
                    {"title": "Commit", "value": "${{ github.sha }}", "short": true},
                    {"title": "Run", "value": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}", "short": false}
                  ]
                }]
              }'
          fi

      - name: Production summary
        run: |
          echo "## Production Deployment" >> $GITHUB_STEP_SUMMARY
          echo "- Environment: production" >> $GITHUB_STEP_SUMMARY
          echo "- URL: ${{ vars.PRODUCTION_URL }}" >> $GITHUB_STEP_SUMMARY
          echo "- Commit: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- Image: \`${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:sha-${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY

  # ===========================================================================
  # QUALITY GATE FINAL
  # ===========================================================================
  quality-gate:
    name: "Quality Gate"
    runs-on: ubuntu-latest
    needs: [lint-python, format-check, type-check, architecture, security-sast, security-sca, secret-scan, test]
    if: always()

    steps:
      - name: Check quality gate
        run: |
          echo "## Quality Gate Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Check | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Lint Python | ${{ needs.lint-python.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Format Check | ${{ needs.format-check.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Type Check | ${{ needs.type-check.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Architecture | ${{ needs.architecture.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Security SAST | ${{ needs.security-sast.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Security SCA | ${{ needs.security-sca.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Secret Scan | ${{ needs.secret-scan.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Tests | ${{ needs.test.result }} |" >> $GITHUB_STEP_SUMMARY

          # Blocking checks
          if [ "${{ needs.lint-python.result }}" == "failure" ]; then
            echo "::error::Lint failed - quality gate blocked"
            exit 1
          fi
          if [ "${{ needs.security-sast.result }}" == "failure" ]; then
            echo "::error::Security SAST failed - quality gate blocked"
            exit 1
          fi
          if [ "${{ needs.test.result }}" == "failure" ]; then
            echo "::error::Tests failed - quality gate blocked"
            exit 1
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Quality Gate: PASSED**" >> $GITHUB_STEP_SUMMARY
